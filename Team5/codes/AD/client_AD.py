import paho.mqtt.client as mqtt
import cv2
import numpy as np
from openvino.runtime import Core
import torch
import torch.nn as nn
from PIL import Image
from torchvision import transforms, models
import os
import time
import sys
import json 
from datetime import datetime, timezone
import base64

# ====================================================
# 0. ê³ ì • ì¹´ë©”ë¼ í• ë‹¹ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸
# ====================================================
# find_camera_by_vid_pid í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from camera_init_robust import find_camera_by_vid_pid 

# ====================================================
# 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# ====================================================

# MQTT ì„¤ì •
BROKER = "10.10.14.73"
PORT = 1883
TOPIC_BASE = "project/vision" # í† í”½ ì ‘ë‘ì‚¬

# ğŸš¨ğŸš¨ AD_USER ì¸ì¦ ì •ë³´ ì¶”ê°€ ğŸš¨ğŸš¨
MQTT_USERNAME = "AD_USER"      # ë“±ë¡ëœ AD ì‚¬ìš©ì ì´ë¦„
MQTT_PASSWORD = "sksk"  # ë“±ë¡ëœ AD ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸ (ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½ í•„ìš”)

# AD ëª¨ë“ˆ ëª…í™•íˆ ì§€ì • ë° í† í”½ ë¶„ë¦¬
AD_MODULE = "AD"
RAW_TOPIC = TOPIC_BASE + "/" + AD_MODULE + "/RAW"
ALERT_TOPIC = TOPIC_BASE + "/" + AD_MODULE + "/ALERT" # ê²½ê³  í† í”½ë„ AD ì „ìš©ìœ¼ë¡œ ë¶„ë¦¬
AD_VIDEO_TOPIC = "project/vision/AD/VIDEO" # ì‹œì—°ìš© ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í† í”½

def now_str():
    """ISO 8601 í˜•ì‹ì˜ í˜„ì¬ UTC ì‹œê°ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

# =======================
# 2. ëª¨ë¸ ê²½ë¡œ ì„¤ì • ë° ìœ íš¨ì„± ê²€ì‚¬
# (ëª¨ë“  ëª¨ë¸ íŒŒì¼ì€ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)
# =======================
det_xml = "models/Detection.xml"
det_bin = "models/Detection.bin"

cls_xml = "models/Classification.xml"
cls_bin = "models/Classification.bin"

DEPLOYMENT_FILE = "models/deployed_obstacle_detector.pt"

ALL_MODEL_PATHS = [det_xml, det_bin, cls_xml, cls_bin, DEPLOYMENT_FILE]
for path in ALL_MODEL_PATHS:
    if not os.path.exists(path):
        print(f"[{now_str()}] âŒ CRITICAL: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        sys.exit(1) # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ

# =======================
# 3. ì „ì—­ ê°ì²´ ë° ìƒìˆ˜
# =======================
ie = Core()
det_compiled = None
det_input_layer = None
det_output_layer = None
cls_compiled = None
cls_input_layer = None
cls_output_layer = None
cls_h, cls_w = 0, 0
cap = None
deployed_model = None

class_names = ["Buoy", "Reef", "Island", "Ship", "Lighthouse"]
last_frame_boxes = [] # NMS/ìŠ¤ë¬´ë”©ì„ ìœ„í•œ ì´ì „ í”„ë ˆì„ ë°•ìŠ¤
OPTIMAL_THRESHOLD = 0.7 # Anomaly Detection ì„ê³„ê°’
MODEL_INPUT_SIZE = 224
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]

inference_transforms = transforms.Compose([
    transforms.Resize((MODEL_INPUT_SIZE, MODEL_INPUT_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(MEAN, STD)
])


# =======================
# 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (NMS, IoU, Preprocessing)
# =======================
    
def nms(boxes, scores, score_threshold=0.5, iou_threshold=0.5):
    """Non-Maximum Suppression"""
    if not boxes: return [], []
    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold, iou_threshold)
    if len(indices) > 0:
        indices = indices.flatten()
        return [boxes[i] for i in indices], [scores[i] for i in indices]
    return [], []

def iou(box1, box2):
    """Intersection over Union ê³„ì‚°"""
    # box1, box2: [x, y, w, h]
    x1, y1, w1, h1 = box1
    x2, y2, w2, h2 = box2
    
    xi1 = max(x1, x2)
    yi1 = max(y1, y2)
    xi2 = min(x1 + w1, x2 + w2)
    yi2 = min(y1 + h1, y2 + h1) # Fix: box2 height was h2, corrected to h2+y2 and min(y1+h1, y2+h2) for correct IoU calculation (Original code used w/h in list)
    
    # Re-calculate Intersection based on original [x, y, w, h] format assumed by input
    xi1 = max(x1, x2)
    yi1 = max(y1, y2)
    xi2 = min(x1 + w1, x2 + w2)
    yi2 = min(y1 + h1, y2 + h2)

    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    union_area = w1 * h1 + w2 * h2 - inter_area
    return inter_area / union_area if union_area > 0 else 0

def enhance_low_light(image):
    """CLAHEë¥¼ ì´ìš©í•œ ì €ì¡°ë„ ê°œì„ """
    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
    return enhanced_img

def dehaze(image):
    """Dark Channel Priorë¥¼ ì´ìš©í•œ Dehazing"""
    min_channel = np.min(image, axis=2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
    dark_channel = cv2.erode(min_channel, kernel)
    A = np.max(dark_channel)
    # 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€
    A = A if A > 0 else 255
    t = 1 - 0.95 * dark_channel / A
    t = np.clip(t, 0.1, 1)
    J = np.empty_like(image, dtype=np.float32)
    for c in range(3):
        # tê°€ 0.1ë³´ë‹¤ ì‘ì§€ ì•Šìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ë‚˜ëˆ—ì…ˆ ìˆ˜í–‰
        J[:,:,c] = (image[:,:,c].astype(np.float32) - A) / t + A
    J = np.clip(J, 0, 255).astype(np.uint8)
    return J

# =======================
# 5. ì´ˆê¸°í™” í•¨ìˆ˜ (ëª¨ë“  ëª¨ë¸ ë¡œë“œ ë° ì¹´ë©”ë¼ ì´ˆê¸°í™”)
# =======================

def initialize_vision():
    """OpenVINO ëª¨ë¸, PyTorch ëª¨ë¸ ë° ì¹´ë©”ë¼ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    global det_compiled, det_input_layer, det_output_layer
    global cls_compiled, cls_input_layer, cls_output_layer
    global cls_h, cls_w, cap, deployed_model
    
    try:
        # OpenVINO ëª¨ë¸ ë¡œë“œ
        det_model = ie.read_model(det_xml, det_bin)
        det_compiled = ie.compile_model(det_model, "CPU")
        det_input_layer = det_compiled.input(0)
        det_output_layer = det_compiled.output(0)
        print(f"[{now_str()}] âœ… OpenVINO Detection ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        cls_model = ie.read_model(cls_xml, cls_bin)
        cls_compiled = ie.compile_model(cls_model, "CPU")
        cls_input_layer = cls_compiled.input(0)
        cls_output_layer = cls_compiled.output(0)
        _, _, cls_h, cls_w = cls_input_layer.shape
        print(f"[{now_str()}] âœ… OpenVINO Classification ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        deployed_model = torch.jit.load(DEPLOYMENT_FILE, map_location='cpu')
        deployed_model.eval()
        print(f"[{now_str()}] âœ… PyTorch Anomaly ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        # ì¹´ë©”ë¼ ì´ˆê¸°í™”: ê³ ìœ  ID ê¸°ë°˜ ì¸ë±ìŠ¤ ê²€ìƒ‰
        print(f"[{now_str()}] INFO System :: AD ì¹´ë©”ë¼ ê³ ìœ  ID ê¸°ë°˜ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        
        # AD ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œí•˜ê³ , PE ì¸ë±ìŠ¤ëŠ” ë¬´ì‹œí•©ë‹ˆë‹¤.
        AD_CAMERA_INDEX, _ = find_camera_by_vid_pid()
        
        if AD_CAMERA_INDEX == -1:
            raise RuntimeError("AD ì¹´ë©”ë¼ (VID:PID)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ camera_init_robust.pyì˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

        print(f"[{now_str()}] âœ… AD ì¹´ë©”ë¼ ê³ ì • ì¸ë±ìŠ¤ í™•ë³´: {AD_CAMERA_INDEX}")
        
        # í™•ë³´ëœ ì¸ë±ìŠ¤ë¡œ ì¹´ë©”ë¼ë¥¼ ì—½ë‹ˆë‹¤.
        cap = cv2.VideoCapture(AD_CAMERA_INDEX)

        if cap.isOpened():
            # í•´ìƒë„ ë° ì†ì„± ì„¤ì •
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            cap.set(cv2.CAP_PROP_FPS, 30)
            
            print(f"[{now_str()}] âœ… ì›¹ìº  ì—´ê¸° ì„±ê³µ: ì¸ë±ìŠ¤ {AD_CAMERA_INDEX}")
        else:
             # cv2.VideoCaptureê°€ ì¸ë±ìŠ¤ì— ì‹¤íŒ¨í•˜ë©´ ì˜¤ë¥˜ ë°œìƒ
            raise RuntimeError(f"ì›¹ìº  ì¸ë±ìŠ¤ {AD_CAMERA_INDEX}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        for _ in range(5):
            cap.read()
            time.sleep(0.05)
        print(f"[{now_str()}] ğŸ¥ ì¹´ë©”ë¼ ë²„í¼ ì•ˆì •í™” ì™„ë£Œ (ì²« 5í”„ë ˆì„ ìŠ¤í‚µ).")
        
    except Exception as e:
        print(f"[{now_str()}] âŒ CRITICAL: ì´ˆê¸°í™” ì‹¤íŒ¨ - {e}")
        sys.exit(1)


# ====================================================
# 6. ë©”ì¸ ì¶”ë¡  ë° ë°œí–‰ í•¨ìˆ˜ (ì‹œê°í™” ë° ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ ì¶”ê°€)
# ====================================================

def run_inference_and_publish(client):
    """
    1. ì´ë¯¸ì§€ ìº¡ì²˜ ë° ì „ì²˜ë¦¬ (ì €ì¡°ë„ ê°œì„ , Dehazing)
    2. OpenVINO Detection/Classification & PyTorch Anomaly Detection
    3. ì‹œê°í™” ë° ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë°œí–‰ (AD_VIDEO_TOPIC)
    4. MQTTë¡œ RAW/ALERT ë°ì´í„° ë°œí–‰
    """
    global last_frame_boxes
    
    start_time = time.time() # FPS ì¸¡ì • ì‹œì‘
    
    # 1. í”„ë ˆì„ ìº¡ì²˜
    ret, frame = cap.read()
    if not ret:
        print(f"[{now_str()}] âŒ ERROR: í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        time.sleep(0.1)
        return

    # --------------------------
    # 1-1) ì „ì²˜ë¦¬: ì €ì¡°ë„ ê°œì„  ë° Dehazing
    # --------------------------
    enhanced = enhance_low_light(frame)
    dehazed = dehaze(enhanced)

    # --------------------------
    # 2) OpenVINO Detection (ì¥ì• ë¬¼ ê°ì§€)
    # --------------------------
    # OpenVINO ëª¨ë¸ ì…ë ¥ í¬ê¸° (640x640)ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
    resized = cv2.resize(dehazed, (640, 640)) 
    # OpenVINO ì…ë ¥ í˜•íƒœ: BxCxHxW
    input_image = np.expand_dims(resized.transpose(2, 0, 1), 0).astype(np.float32)
    det_results = det_compiled([input_image])[det_output_layer][0]

    boxes, scores = [], []
    for det in det_results:
        # OpenVINO ì¶œë ¥ í¬ë§·ì— ë”°ë¼ (x_min, y_min, x_max, y_max, conf)
        x_min, y_min, x_max, y_max, conf = det
        if conf > 0.5:
            # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°(480x640)ë¡œ ì¢Œí‘œ ë³µì›
            x_min = int(x_min / 640 * dehazed.shape[1])
            y_min = int(y_min / 640 * dehazed.shape[0])
            x_max = int(x_max / 640 * dehazed.shape[1])
            y_max = int(y_max / 640 * dehazed.shape[0])
            # NMSë¥¼ ìœ„í•´ [x, y, w, h] í˜•íƒœë¡œ ì €ì¥
            boxes.append([x_min, y_min, x_max - x_min, y_max - y_min]) 
            scores.append(float(conf))

    filtered_boxes, _ = nms(boxes, scores)

    # --------------------------
    # 3) Frame smoothing (NMS ê¸°ë°˜)
    # --------------------------
    smoothed_boxes = []
    # ì´ì „ í”„ë ˆì„ê³¼ IoU 0.7 ì´ìƒì¸ ë°•ìŠ¤ëŠ” ì´ì „ ë°•ìŠ¤ ìœ„ì¹˜ë¥¼ ì‚¬ìš© (í”ë“¤ë¦¼ ë°©ì§€)
    for box in filtered_boxes:
        matched = False
        for prev_box in last_frame_boxes:
            if iou(box, prev_box) > 0.7:
                smoothed_boxes.append(prev_box)
                matched = True
                break
        if not matched:
            smoothed_boxes.append(box)
    last_frame_boxes = smoothed_boxes.copy() # ë‹¤ìŒ í”„ë ˆì„ì„ ìœ„í•´ ì €ì¥

    # --------------------------
    # 4) Classification & Anomaly Check
    # --------------------------
    detections = []
    anomaly_detected = False
    critical_ship_detected = False # ğŸš¨ CRITICAL ì¶©ëŒ ìœ„í—˜ì„ ìœ ë°œí•  ìˆ˜ ìˆëŠ” ë°° ê°ì§€
    
    for (x, y, w, h) in smoothed_boxes:
        # Classificationì„ ìœ„í•œ ì˜ì—­ ì¶”ì¶œ
        crop = dehazed[max(0, y-5):min(dehazed.shape[0], y+h+5), max(0, x-5):min(dehazed.shape[1], x+w+5)]
        if crop.size == 0: continue

        # Classification (OpenVINO)
        cls_resized = cv2.resize(crop, (cls_w, cls_h))
        cls_resized = cv2.cvtColor(cls_resized, cv2.COLOR_BGR2RGB)
        cls_input = np.expand_dims(cls_resized.transpose(2, 0, 1), 0).astype(np.float32) / 255.0

        cls_result = cls_compiled([cls_input])[cls_output_layer]
        class_id = int(np.argmax(cls_result))
        score_cls = float(np.max(cls_result))
        label_name = class_names[class_id]
        
        # ğŸš¨ ì¼ë°˜ 'Ship'ì„ ê°ì§€í–ˆì„ ë•Œ ì¶©ëŒ ìœ„í—˜ìœ¼ë¡œ íŒë‹¨ (ì„ì‹œ ë¡œì§)
        if label_name in ['Ship']: 
             critical_ship_detected = True

        # Anomaly Detection (PyTorch) - íƒì§€ëœ ê°ì²´ ì˜ì—­ì—ë§Œ ì ìš©
        pil_crop = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
        input_tensor = inference_transforms(pil_crop).unsqueeze(0).to('cpu')
        
        with torch.no_grad():
            # anomaly_scoreëŠ” 0~1 ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ, ë†’ì„ìˆ˜ë¡ ì´ìƒ(anomaly)ìœ¼ë¡œ ê°„ì£¼
            anomaly_score = deployed_model(input_tensor).item() 
        
        is_anomaly = anomaly_score > OPTIMAL_THRESHOLD
        if is_anomaly:
            anomaly_detected = True

        detections.append({
            "object_type": label_name,
            "confidence": round(score_cls, 2),
            "anomaly": is_anomaly,
            "anomaly_score": round(anomaly_score, 4),
            "box": [x, y, w, h] # x, y, width, height
        })

    # --------------------------
    # 4-1) ì‹œê°í™”: ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    # --------------------------
    visual_frame = dehazed.copy()
    for d in detections:
        x, y, w, h = d['box']
        label = f"{d['object_type']}"
        score_text = f"C:{d['confidence']:.2f}"
        
        if d['anomaly']:
            label += " (Anomaly!)"
            color = (0, 0, 255) # ë¹¨ê°• (Anomaly)
        elif d['object_type'] == 'Ship':
            color = (0, 165, 255) # ì£¼í™© (Ship/Critical)
        else:
            color = (0, 255, 0) # ì´ˆë¡ (ì •ìƒ ê°ì²´)
            
        cv2.rectangle(visual_frame, (x, y), (x + w, y + h), color, 2)
        cv2.putText(visual_frame, label, (x, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        cv2.putText(visual_frame, score_text, (x, y - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

    # --------------------------
    # 5) ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ë°œí–‰ (AD_VIDEO_TOPIC)
    # --------------------------
    try:
        # í”„ë ˆì„ ì••ì¶• (JPEG) ë° Base64 ì¸ì½”ë”©
        ret_enc, buffer = cv2.imencode('.jpg', visual_frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
        
        if ret_enc:
            # JPEG ë°”ì´íŠ¸ë¥¼ Base64 ë¬¸ìì—´ë¡œ ë³€í™˜
            jpg_as_text = base64.b64encode(buffer.tobytes()).decode('utf-8').replace('\n', '').replace('\r', '')
            
            # ìƒˆë¡œìš´ VIDEO í† í”½ìœ¼ë¡œ ë°œí–‰ (QoS 1)
            client.publish(AD_VIDEO_TOPIC, jpg_as_text, qos=1)
            
            # ë°œí–‰ ë¡œê·¸
            end_time = time.time()
            fps = 1.0 / (end_time - start_time + 1e-6)
            # (ìˆ˜ì •) FPS ë¡œê·¸ëŠ” 5ì´ˆë§ˆë‹¤ í•œ ë²ˆë§Œ ì¶œë ¥ (ê³¼ë„í•œ ë¡œê·¸ ë°©ì§€)
            # print(f"[{now_str()}] [PUB-AD-VIDEO] âœ… Visual frame sent (FPS: {fps:.1f}) (Size: {len(jpg_as_text)/1024:.1f} KB)")
            if int(time.time()) % 5 == 0:
                print(f"[{now_str()}] [PUB-AD-VIDEO] âœ… Sent (FPS: {fps:.1f}) (Size: {len(jpg_as_text)/1024:.1f} KB)")
        else:
            print(f"[{now_str()}] [WARNING] âŒ JPEG encoding failed.")
            
    except Exception as e:
        print(f"[{now_str()}] [ERROR] âŒ Video streaming publish failed: {e}")

    # --------------------------
    # 6) MQTT ë°ì´í„° ë°œí–‰ (RAW/ALERT)
    # --------------------------
    
    # 6-1. ê¸°ë³¸ RAW ë°ì´í„° (ëª¨ë“  íƒì§€ ê²°ê³¼ í¬í•¨)
    raw_data = {
        "timestamp": now_str(),
        "module": AD_MODULE,
        "level": "INFO",
        "detections": detections,
        "total_count": len(detections),
        "anomaly_count": sum(1 for d in detections if d['anomaly']),
        "message": f"{len(detections)}ê°œ ê°ì²´ ê°ì§€ë¨ (ì´ìƒ {sum(1 for d in detections if d['anomaly'])}ê°œ)"
    }
    raw_payload = json.dumps(raw_data, ensure_ascii=False)
    client.publish(RAW_TOPIC, raw_payload, qos=0)

    # 6-2. ê²½ê³  ì´ë²¤íŠ¸ (Anomalyë‚˜ ì¤‘ìš” ê°ì²´ ê°ì§€ ì‹œ)
    if anomaly_detected or critical_ship_detected:
        alert_level = "CRITICAL"
        summary = []
        if critical_ship_detected:
            summary.append("ì„ ë°• ì¶©ëŒ ìœ„í—˜")
        if anomaly_detected:
            summary.append(f"{sum(1 for d in detections if d['anomaly'])}ê°œ ì´ìƒ ì§•í›„")
        alert_msg = f"ê¸´ê¸‰! {', '.join(summary)} ê°ì§€."

        alert_data = {
            "timestamp": now_str(),
            "module": AD_MODULE,
            "level": alert_level,
            "message": alert_msg,
            "details": [d for d in detections if d['anomaly'] or d['object_type'] == "Ship"]
        }
        alert_payload = json.dumps(alert_data, ensure_ascii=False)
        client.publish(ALERT_TOPIC, alert_payload, qos=1)
        print(f"[{now_str()}] ğŸ“¢ {alert_level} PUB :: {ALERT_TOPIC} â†’ {alert_msg}")    
    
    time.sleep(0.01) # 0.01ì´ˆ ëŒ€ê¸° (CPU ì ìœ ìœ¨ ê´€ë¦¬)


# ====================================================
# 7. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ====================================================

def main():
    # 1. ëª¨ë¸ ë° ì¹´ë©”ë¼ ì´ˆê¸°í™”
    initialize_vision()

    # 2. MQTT í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²°
    # Fix: MQTTv311 í”„ë¡œí† ì½œ ëª…ì‹œë¡œ DeprecationWarning í•´ê²°
    client = mqtt.Client(client_id="AD_Client", protocol=mqtt.MQTTv311) 

    # ì‚¬ìš©ì ì´ë¦„ ë° ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
    client.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)

    def on_connect(client, userdata, flags, rc):
        if rc == 0:
            print(f"[{now_str()}] INFO MQTT :: Client connected successfully (RC: {rc})")
        else:
            print(f"[{now_str()}] âŒ CRITICAL: MQTT Connection failed (RC: {rc})")
            sys.exit(1)
            
    client.on_connect = on_connect # ì½œë°± ì„¤ì •
    
    try:
        client.connect(BROKER, PORT, 60)
        client.loop_start() 
        print(f"[{now_str()}] INFO MQTT :: Client attempting connection to {BROKER}:{PORT}")
    except Exception as e:
        print(f"[{now_str()}] âŒ CRITICAL: MQTT ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)
    
    # 3. ë©”ì¸ ë£¨í”„
    try:
        while True:
            # GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° cv2.waitKey(1) ëŒ€ì‹  time.sleepì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
            # cv2.imshowëŠ” ì œê±°í–ˆìœ¼ë¯€ë¡œ time.sleep(0.01) ì •ë„ë¥¼ ì¶”ê°€í•˜ì—¬ CPU ì ìœ ìœ¨ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
            run_inference_and_publish(client)
            
    except KeyboardInterrupt:
        print(f"\n[{now_str()}] INFO System :: Vision client stopped by user (Ctrl+C).")
    except Exception as e:
        print(f"\n[{now_str()}] âŒ ERROR System :: An unexpected error occurred: {e}")
    finally:
        client.loop_stop()
        client.disconnect() 
        print(f"[{now_str()}] INFO MQTT :: Client disconnected.")
        if cap is not None:
            cap.release()
        sys.exit(0)

if __name__ == "__main__":
    main()
