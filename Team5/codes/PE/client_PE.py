import os
import cv2
import time
import torch
import argparse
import numpy as np
import tensorflow as tf
from ultralytics import YOLO
import paho.mqtt.client as mqtt
import json
from datetime import datetime, timezone
import base64

# ====================================================
# 0. ê³ ì • ì¹´ë©”ë¼ í• ë‹¹ì„ ìœ„í•œ ëª¨ë“ˆ ì„í¬íŠ¸ (ìˆ˜ì •ëœ ë¶€ë¶„ 1/2)
# camera_init_robust.py íŒŒì¼ì´ ì´ ìŠ¤í¬ë¦½íŠ¸ì™€ ê°™ì€ ê²½ë¡œì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
# ====================================================
from camera_init_robust import find_camera_by_vid_pid 

# ============================================
# MQTT ì„¤ì • (ì„œë²„ì™€ ë™ì¼í•´ì•¼ í•©ë‹ˆë‹¤)
# ============================================
MQTT_BROKER = "10.10.14.73" 
MQTT_PORT = 1883
TOPIC_BASE = "project/vision"

# ğŸš¨ğŸš¨ PE_USER ì¸ì¦ ì •ë³´ ì¶”ê°€ ğŸš¨ğŸš¨
MQTT_USERNAME = "PE_USER"      # ë“±ë¡ëœ PE ì‚¬ìš©ì ì´ë¦„
MQTT_PASSWORD = "sksk"  # ë“±ë¡ëœ PE ì‚¬ìš©ì ë¹„ë°€ë²ˆí˜¸

# ìˆ˜ì •: ëª¨ë“ˆ ì´ë¦„ ë° í† í”½ ë¶„ë¦¬
PE_MODULE = "PE"
RAW_TOPIC = TOPIC_BASE + "/" + PE_MODULE + "/RAW"
ALERT_TOPIC = TOPIC_BASE + "/" + PE_MODULE + "/ALERT" # ê²½ê³  í† í”½ë„ AD ì „ìš©ìœ¼ë¡œ ë¶„ë¦¬
PE_VIDEO_TOPIC = "project/vision/PE/VIDEO" # ì‹œì—°ìš© ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í† í”½

def now_str():
    """ISO 8601 í˜•ì‹ì˜ í˜„ì¬ UTC ì‹œê°ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

# ============================================
# ì„¤ì •
# ============================================
# ë””ë²„ê·¸ ëª¨ë“œëŠ” Trueë¡œ ìœ ì§€í•˜ì—¬ ë¡œê·¸ ì¶œë ¥ì€ ê³„ì†í•©ë‹ˆë‹¤.
DEBUG_MODE = True  # Trueë¡œ í•˜ë©´ ìƒì„¸ ë¡œê·¸

# ìœ„í—˜êµ¬ì—­ ì„¤ì • (ì ˆëŒ€ ì¢Œí‘œ)
USE_RATIO = False
DANGER_X_MIN = None
DANGER_X_MAX = 200
DANGER_Y_MIN = None
DANGER_Y_MAX = None

# ë¹„ìœ¨ ë°©ì‹ (USE_RATIO = Trueì¼ ë•Œë§Œ ì‚¬ìš©)
DANGER_X_RATIO_MIN = None
DANGER_X_RATIO_MAX = 0.3
DANGER_Y_RATIO_MIN = None
DANGER_Y_RATIO_MAX = None

ZONE_WARNING_TIME = 3
ZONE_ALERT_TIME = 5
SHOW_DANGER_AREA = False # í™”ë©´ ì¶œë ¥ì„ ì œê±°í–ˆìœ¼ë¯€ë¡œ ì´ í”Œë˜ê·¸ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ë¡œì§ì€ ìœ ì§€í•©ë‹ˆë‹¤.
DANGER_AREA_COLOR = (0, 0, 255)

# ë„˜ì–´ì§ íŒë‹¨ ì„¤ì •
FALL_CONFIDENCE_THRESHOLD = 0.65
FALL_FRAMES = 3 # ì´ í”„ë ˆì„ ìˆ˜ë§Œí¼ ì—°ì†ë˜ì–´ì•¼ ë‚™ìƒ í™•ì •

# MQTT RAW ë°ì´í„° ë°œí–‰ ì£¼ê¸° (í”„ë ˆì„)
RAW_PUBLISH_INTERVAL = 15

# ============================================
# MoveNet í¬ì¦ˆ ì¶”ì • ëª¨ë¸
# ============================================
class MoveNetPose:
    """MoveNet Thunder - ë¼ì¦ˆë² ë¦¬íŒŒì´5 ìµœì í™”"""
    
    def __init__(self, model_type='thunder', device='cpu'):
        print(f"Loading MoveNet {model_type}...")
        self.model_type = model_type
        self.input_size = 256 if model_type == 'thunder' else 192
        self.use_tflite = False
        
        # TFLite íŒŒì¼ì„ ìš°ì„  ì‹œë„
        model_path = f'movenet_{model_type}.tflite'
        if os.path.exists(model_path):
            try:
                # TFLite ëª¨ë¸ ë¡œë“œ
                # WARNING: TensorFlow Lite InterpreterëŠ” RPiì—ì„œ ì‹¤í–‰ ì‹œ CPU ìµœì í™”ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.
                self.interpreter = tf.lite.Interpreter(model_path=model_path)
                self.interpreter.allocate_tensors()
                self.use_tflite = True
                print(f"[{now_str()}] âœ… Loaded TFLite model successfully!")
                return
            except Exception as e:
                print(f"[{now_str()}] âŒ TFLite loading failed: {e}")
                
        # TFLite ë¡œë“œ ì‹¤íŒ¨ ì‹œ, ìµœì†Œí•œì˜ ê¸°ëŠ¥ì€ ìœ ì§€ (TFLite ë¡œë“œê°€ ì„±ê³µí•´ì•¼ ì‘ë™)
        if not self.use_tflite:
             print(f"[{now_str()}] âš ï¸ MoveNet TFLite model not found or failed to load. Pose estimation disabled.")

    
    def predict(self, frame, bboxes, scores=None):
        """
        í”„ë ˆì„ ì•ˆì˜ ì—¬ëŸ¬ ì‚¬ëŒì— ëŒ€í•œ ìì„¸ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        """
        if bboxes is None or len(bboxes) == 0:
            return []

        poses = []
        # TFLite Interpreterê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
        if not hasattr(self, 'interpreter') or not self.use_tflite:
            return []

        for i, bbox in enumerate(bboxes):
            x1, y1, x2, y2 = bbox.astype(int)
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)
            
            if x2 <= x1 or y2 <= y1:
                continue
                
            crop_img = frame[y1:y2, x1:x2]
            crop_height, crop_width, _ = crop_img.shape
            
            # í…ì„œí”Œë¡œìš° ë³€í™˜ (TFLite ì‚¬ìš© ì‹œ í•„ìš”)
            input_image = tf.convert_to_tensor(crop_img, dtype=tf.uint8)
            
            # ëª¨ë¸ ì…ë ¥ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ ë° íŒ¨ë”©
            resized_img = tf.image.resize_with_pad(input_image, self.input_size, self.input_size)
            input_img_tensor = tf.cast(resized_img, dtype=tf.uint8)
            input_batch = tf.expand_dims(input_img_tensor, axis=0)
            
            # TFLite Inference
            input_details = self.interpreter.get_input_details()
            self.interpreter.set_tensor(input_details[0]['index'], input_batch)
            self.interpreter.invoke()
            
            output_details = self.interpreter.get_output_details()
            keypoints_with_scores = np.squeeze(self.interpreter.get_tensor(output_details[0]['index']))
            
            # ì¢Œí‘œ ë³€í™˜ ë¡œì§ (Movenetì˜ ì¶œë ¥ ì¢Œí‘œë¥¼ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜)
            if crop_height > crop_width:
                scale_factor = self.input_size / crop_height
                new_width = crop_width * scale_factor
                padd_x = (self.input_size - new_width) / 2
                padd_y = 0
                scale_x = new_width / crop_width
                scale_y = self.input_size / crop_height
            else:
                scale_factor = self.input_size / crop_width
                new_height = crop_height * scale_factor
                padd_x = 0
                padd_y = (self.input_size - new_height) / 2
                scale_x = self.input_size / crop_width
                scale_y = new_height / crop_height

            keypoints = np.zeros((17, 3), dtype=np.float32)
            
            norm_y = keypoints_with_scores[:, 0]
            norm_x = keypoints_with_scores[:, 1]
            
            # ë³€í™˜ëœ ì¢Œí‘œë¥¼ ì›ë³¸ bbox ìœ„ì¹˜ì— ë§ê²Œ ì¡°ì •
            keypoints[:, 0] = ((norm_x * self.input_size - padd_x) / scale_x) + x1
            keypoints[:, 1] = ((norm_y * self.input_size - padd_y) / scale_y) + y1
            keypoints[:, 2] = keypoints_with_scores[:, 2] # Confidence score
            
            proposal_score = float(np.mean(keypoints[:, 2]))
            
            poses.append({
                'keypoints': keypoints,  # [17, 3] í˜•íƒœë¡œ í†µì¼
                'proposal_score': proposal_score,
                'bbox': bbox
            })
        return poses

# ============================================
# 4. ë£° ê¸°ë°˜ ë‚™ìƒ ê°ì§€ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================
def estimate_motion(prev_kp, curr_kp):
    """í‰ê·  í‚¤í¬ì¸íŠ¸ ì´ë™ëŸ‰ (ê±·ê¸° ì¸ì‹ìš©)"""
    if prev_kp is None or len(prev_kp) == 0 or prev_kp.shape != curr_kp.shape:
        return 0.0
    
    # ì‹ ë¢°ë„ ì²´í¬
    valid = (prev_kp[:, 2] > 0.2) & (curr_kp[:, 2] > 0.2)
    if np.sum(valid) < 5:
        return 0.0
    
    # ìœ íš¨í•œ í‚¤í¬ì¸íŠ¸ë§Œ ì‚¬ìš©í•˜ì—¬ ì´ë™ëŸ‰ ê³„ì‚°
    diffs = np.linalg.norm(curr_kp[valid, :2] - prev_kp[valid, :2], axis=1)
    motion = float(np.mean(diffs))
    
    if DEBUG_MODE:
        print(f"    Motion calculation: {np.sum(valid)} valid points, motion={motion:.2f}")
    
    return motion

def calculate_body_angle(keypoints):
    """ëª¸ì˜ ê¸°ìš¸ê¸° ê°ë„ (0Â° = ì™„ì „ ìˆ˜ì§, 90Â° = ì™„ì „ ìˆ˜í‰)"""
    if len(keypoints) < 13:
        return None

    valid_shoulder = []
    valid_hip = []

    # ì–´ê¹¨ ì¤‘ì‹¬ì  ê³„ì‚°
    if keypoints[5][2] > 0.2: # Left Shoulder
        valid_shoulder.append(keypoints[5][:2])
    if keypoints[6][2] > 0.2: # Right Shoulder
        valid_shoulder.append(keypoints[6][:2])
        
    # ê³¨ë°˜ ì¤‘ì‹¬ì  ê³„ì‚°
    if keypoints[11][2] > 0.2: # Left Hip
        valid_hip.append(keypoints[11][:2])
    if keypoints[12][2] > 0.2: # Right Hip
        valid_hip.append(keypoints[12][:2])

    if len(valid_shoulder) == 0 or len(valid_hip) == 0:
        return None

    shoulder_center = np.mean(valid_shoulder, axis=0)
    hip_center = np.mean(valid_hip, axis=0)

    dx = hip_center[0] - shoulder_center[0]
    dy = shoulder_center[1] - hip_center[1] # yì¶•ì€ ì•„ë˜ë¡œ ê°ˆìˆ˜ë¡ ì»¤ì§€ë¯€ë¡œ ì–´ê¹¨ y - ê³¨ë°˜ yë¡œ ê³„ì‚°
    
    # ìˆ˜ì§(yì¶•)ê³¼ì˜ ê°ë„ ê³„ì‚° (0ë„: ìˆ˜ì§, 90ë„: ìˆ˜í‰)
    angle = np.degrees(np.arctan2(abs(dx), abs(dy)))
    return angle


def get_body_aspect_ratio(keypoints):
    """ëª¸ì˜ ê°€ë¡œ/ì„¸ë¡œ ë¹„ìœ¨"""
    valid_points = keypoints[keypoints[:, 2] > 0.15]
    
    if len(valid_points) < 3:
        return None
    
    x_coords = valid_points[:, 0]
    y_coords = valid_points[:, 1]
    
    width = x_coords.max() - x_coords.min()
    height = y_coords.max() - y_coords.min()
    
    if height < 5:
        return None
    
    return width / height


def detect_fall_rule_based(keypoints, prev_keypoints=None):
    """í–¥ìƒëœ ë£° ê¸°ë°˜ ìƒíƒœ ì¸ì‹"""
    
    angle = calculate_body_angle(keypoints)
    ratio = get_body_aspect_ratio(keypoints)
    motion = estimate_motion(prev_keypoints, keypoints)

    conf = float(np.mean(keypoints[:, 2]))

    if angle is None or ratio is None:
        return 'Unknown', conf, {}
    
    details = {"angle": f"{angle:.1f}", "ratio": f"{ratio:.2f}", "motion": f"{motion:.1f}"}
    
    if DEBUG_MODE:
        print(f"  DEBUG >>> Angle: {angle:.1f}Â°, Ratio: {ratio:.2f}, Motion: {motion:.1f}")

    # 1. ëˆ•ê±°ë‚˜ ë„˜ì–´ì§„ ìƒíƒœ (ìˆ˜í‰ì— ê°€ê¹Œì›€, angle > 50)
    if angle > 50:
        if ratio > 1.0:
            if motion < 7:
                return 'Lying Down', conf * 0.95, details
            else:
                # ë†’ì€ ì´ë™ëŸ‰ + ìˆ˜í‰ ìì„¸ = ë„˜ì–´ì§€ëŠ” ì¤‘ (Fall Down)
                return 'Fall Down', conf * 1.0, details
        else:
            return 'Unknown', conf, details

    # 2. ì•‰ì€ ìƒíƒœ (ì–´ëŠ ì •ë„ ê¸°ìš¸ì–´ì§, 10 <= angle < 50)
    elif 10 <= angle < 50 and ratio > 0.5:
        return 'Sitting', conf * 0.9, details
    
    # 3. ì„œ ìˆê±°ë‚˜ ê±·ëŠ” ìƒíƒœ (ê±°ì˜ ìˆ˜ì§, angle < 10)
    elif angle < 10:
        if motion > 2:
            return 'Walking', conf, details
        else:
            return 'Standing', conf, details
    
    else: 
        return 'Unknown', conf, details

def get_location_details(bbox):
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ìš©í•´ ì¤‘ì‹¬ x, í•˜ë‹¨ y ì¢Œí‘œë¥¼ ë°˜í™˜"""
    x1, y1, x2, y2 = bbox
    center_x = (x1 + x2) / 2
    bottom_y = y2
    return int(center_x), int(bottom_y)

def is_in_danger_zone(bbox, frame_width, frame_height):
    """ë°”ìš´ë”©ë°•ìŠ¤ê°€ ìœ„í—˜êµ¬ì—­ì— ìˆëŠ”ì§€ í™•ì¸"""
    center_x, bottom_y = get_location_details(bbox)
    
    if USE_RATIO:
        x_min = int(frame_width * DANGER_X_RATIO_MIN) if DANGER_X_RATIO_MIN is not None else 0
        x_max = int(frame_width * DANGER_X_RATIO_MAX) if DANGER_X_RATIO_MAX is not None else frame_width
        y_min = int(frame_height * DANGER_Y_RATIO_MIN) if DANGER_Y_RATIO_MIN is not None else 0
        y_max = int(frame_height * DANGER_Y_RATIO_MAX) if DANGER_Y_RATIO_MAX is not None else frame_height
    else:
        x_min = DANGER_X_MIN if DANGER_X_MIN is not None else 0
        x_max = DANGER_X_MAX if DANGER_X_MAX is not None else frame_width
        y_min = DANGER_Y_MIN if DANGER_Y_MIN is not None else 0
        y_max = DANGER_Y_MAX if DANGER_Y_MAX is not None else frame_height
    
    in_danger_x = True
    if x_min is not None and center_x < x_min:
        in_danger_x = False
    if x_max is not None and center_x > x_max:
        in_danger_x = False
    
    in_danger_y = True
    if y_min is not None and bottom_y < y_min:
        in_danger_y = False
    if y_max is not None and bottom_y > y_max:
        in_danger_y = False
    
    return in_danger_x and in_danger_y

# ì‹œê°í™” ë”ë¯¸ í•¨ìˆ˜
def draw_danger_area(frame):
    return frame

def draw_zone_warnings(frame, zone_warnings):
    return frame

# ============================================
# ê°„ë‹¨í•œ íŠ¸ë˜ì»¤ (IoU ê¸°ë°˜)
# ============================================

class SimpleTracker:
    """ê°„ë‹¨í•œ IoU ê¸°ë°˜ íŠ¸ë˜ì»¤"""
    
    def __init__(self, max_age=50):
        self.tracks = {}
        self.next_id = 1
        self.max_age = max_age
    
    def update(self, detections):
        """
        detections: List of {'bbox': [x1,y1,x2,y2], 'keypoints': array, 'score': float}
        """
        # ê¸°ì¡´ íŠ¸ë™ ë‚˜ì´ ì¦ê°€
        for track_id in list(self.tracks.keys()):
            self.tracks[track_id]['age'] += 1
            if self.tracks[track_id]['age'] > self.max_age:
                del self.tracks[track_id]
        
        # IoU ë§¤ì¹­
        for det in detections:
            best_iou = 0
            best_id = None
            
            for track_id, track in self.tracks.items():
                iou = self._calculate_iou(det['bbox'], track['bbox'])
                if iou > best_iou and iou > 0.3:
                    best_iou = iou
                    best_id = track_id
            
            if best_id is not None:
                # ê¸°ì¡´ íŠ¸ë™ ì—…ë°ì´íŠ¸
                self.tracks[best_id]['bbox'] = det['bbox']
                self.tracks[best_id]['keypoints'].append(det['keypoints'])
                if len(self.tracks[best_id]['keypoints']) > 30:
                    self.tracks[best_id]['keypoints'].pop(0)
                self.tracks[best_id]['age'] = 0
            else:
                # ìƒˆ íŠ¸ë™ ìƒì„±
                self.tracks[self.next_id] = {
                    'bbox': det['bbox'],
                    'keypoints': [det['keypoints']],
                    'age': 0
                }
                self.next_id += 1
        
        # í˜„ì¬ í™œì„± íŠ¸ë™ ID ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return list(self.tracks.keys())
    
    def _calculate_iou(self, box1, box2):
        """IoU ê³„ì‚°"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])
        
        if x2 < x1 or y2 < y1:
            return 0.0
        
        intersection = (x2 - x1) * (y2 - y1)
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection
        
        return intersection / (union + 1e-6)

# ============================================
# YOLOv8 ê²€ì¶œê¸°
# ============================================

class YOLOv8_Detector:
    def __init__(self, model_name='yolov8n.pt', conf_thres=0.65, device='cpu'):
        self.model = YOLO(model_name)
        self.conf_thres = conf_thres
        self.device = device
    
    def detect(self, frame):
        """ì‚¬ëŒ ê²€ì¶œ"""
        results = self.model.predict(
            frame,
            conf=self.conf_thres,
            classes=[0],  # person only
            device=self.device,
            verbose=False
        )
        
        if len(results) == 0 or len(results[0].boxes) == 0:
            return [], []
        
        boxes = results[0].boxes
        bboxes = []
        scores = []
        
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = box.conf[0].cpu().numpy()
            
            bboxes.append([x1, y1, x2, y2])
            scores.append(conf)
        
        return np.array(bboxes, dtype=np.float32), np.array(scores, dtype=np.float32)

# ì‹œê°í™” ë”ë¯¸ í•¨ìˆ˜
def draw_skeleton(frame, keypoints):
    return frame

# ============================================
# MQTT ë°œí–‰ í•¨ìˆ˜
# (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
# ============================================
def on_connect(client, userdata, flags, rc):
    """MQTT ì—°ê²° ì½œë°±"""
    if rc == 0:
        print(f"[{now_str()}] âœ… MQTT Connected successfully.")
    else:
        print(f"[{now_str()}] âŒ MQTT Connection failed with code {rc}")

def publish_mqtt_message(client, topic, payload):
    """JSON ë©”ì‹œì§€ë¥¼ MQTTë¡œ ë°œí–‰"""
    try:
        json_payload = json.dumps(payload, ensure_ascii=False)
        client.publish(topic, json_payload, qos=0)
        if DEBUG_MODE:
            # ìˆ˜ì •: RAW/ALERTì— ë”°ë¼ ë‹¤ë¥¸ ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥
            msg_type = "ALERT" if "ALERT" in topic else "RAW"
            level = payload.get("level", "N/A")
            print(f"[{now_str()}] [MQTT SEND - {msg_type}:{level}] {topic}")
    except Exception as e:
        print(f"[{now_str()}] [MQTT ERROR] Failed to publish to {topic}: {e}")


# ============================================
# ë©”ì¸
# ============================================

def main():
    parser = argparse.ArgumentParser(description='Raspberry Pi 5 Optimized Fall Detection')
    # --- [!] ì¹´ë©”ë¼ ì¸ë±ìŠ¤ë¥¼ args.camera ëŒ€ì‹  find_camera_by_vid_pidë¡œ ê²°ì • ---
    parser.add_argument('--camera', type=str, default='0', help='Camera source or video path (This is now overridden by fixed index logic)')
    # --------------------------------------------------------------------------
    parser.add_argument('--device', type=str, default='cpu', help='cpu only for RPi5')
    parser.add_argument('--model', type=str, default='thunder', choices=['thunder', 'lightning'])
    parser.add_argument('--save_out', type=str, default='', help='Save output video (GUI ì œê±°ë¡œ ì´ ê¸°ëŠ¥ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)')
    parser.add_argument('--show_skeleton', action='store_true', help='Show skeleton (GUI ì œê±°ë¡œ ì´ ê¸°ëŠ¥ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤)')
    args = parser.parse_args()
    
    print("="*60)
    print("Raspberry Pi 5 Optimized Fall Detection System (MQTT PE Client)")
    print("- Pose: MoveNet " + args.model.title())
    print("- Detection: Rule-based")
    print("- Device: CPU")
    print(f"- MQTT Broker: {MQTT_BROKER}:{MQTT_PORT} / Module: {PE_MODULE}")
    print("="*60)
    
    # 1. ëª¨ë¸ ë¡œë“œ
    print("\n1ï¸âƒ£ Loading models...")
    detector = YOLOv8_Detector(model_name='yolov8n.pt', conf_thres=0.5, device='cpu')
    pose_model = MoveNetPose(model_type=args.model)
    
    # 2. íŠ¸ë˜ì»¤
    tracker = SimpleTracker(max_age=50)
    
    # 3. MQTT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    mqtt_client = mqtt.Client(client_id="PE_Client", protocol=mqtt.MQTTv311)
    
    # ì‚¬ìš©ì ì´ë¦„ ë° ë¹„ë°€ë²ˆí˜¸ ì„¤ì •
    mqtt_client.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)

    mqtt_client.on_connect = on_connect
    try:
        mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
        mqtt_client.loop_start()
    except Exception as e:
        print(f"[{now_str()}] âŒ Failed to connect to MQTT broker: {e}")
        
    # 4. ì¹´ë©”ë¼ ì´ˆê¸°í™” (ìˆ˜ì •ëœ ë¶€ë¶„ 2/2)
    print("\n2ï¸âƒ£ Opening camera...")
    
    # ============================================================
    # ğŸš¨ ì¹´ë©”ë¼ ì´ˆê¸°í™” ë¡œì§ ìˆ˜ì •: ê³ ì • ì¸ë±ìŠ¤ í• ë‹¹ ğŸš¨
    # find_camera_by_vid_pidë¥¼ ì‚¬ìš©í•˜ì—¬ PE ì¹´ë©”ë¼ì˜ ê³ ì • ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    # ============================================================
    print(f"[{now_str()}] INFO System :: PE ì¹´ë©”ë¼ ê³ ìœ  ID ê¸°ë°˜ ì¸ë±ìŠ¤ ê²€ìƒ‰ ì¤‘...")
    
    # AD ì¸ë±ìŠ¤ëŠ” ë¬´ì‹œí•˜ê³ , PE ì¸ë±ìŠ¤ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    _, PE_CAMERA_INDEX = find_camera_by_vid_pid()
    
    if PE_CAMERA_INDEX == -1:
        print(f"[{now_str()}] âŒ CRITICAL: PE ì¹´ë©”ë¼ (VID:PID)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê±°ë‚˜ camera_init_robust.pyì˜ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        mqtt_client.loop_stop()
        return

    print(f"[{now_str()}] âœ… PE ì¹´ë©”ë¼ ê³ ì • ì¸ë±ìŠ¤ í™•ë³´: {PE_CAMERA_INDEX}")
    
    # í™•ë³´ëœ ì¸ë±ìŠ¤ë¡œ ì¹´ë©”ë¼ë¥¼ ì—½ë‹ˆë‹¤.
    cap = cv2.VideoCapture(PE_CAMERA_INDEX)
    
    if not cap.isOpened():
        print(f"[{now_str()}] âŒ Cannot open camera at fixed index {PE_CAMERA_INDEX}! Check source or permissions.")
        mqtt_client.loop_stop()
        return
    print(f"[{now_str()}] âœ… Camera opened")

    # ìƒíƒœ ë³€ìˆ˜
    fall_counters = {}
    zone_timers = {}
    
    # Alert ì „ì†¡ ìƒíƒœ (ì¤‘ë³µ ì „ì†¡ ë°©ì§€)
    alert_sent_fall = {}
    alert_sent_zone = {}

    fps_time = time.time()
    frame_count = 0
    
    print(f"[{now_str()}] 3ï¸âƒ£ Starting detection... (Press Ctrl+C to quit)\n")
    
    while True:
        try:
            ret, frame = cap.read()
            if not ret:
                print(f"[{now_str()}] End of stream or video.")
                break
            
            frame_count += 1
            h, w = frame.shape[:2]
            current_time = time.time()
            
            # ìœ„í—˜êµ¬ì—­ ê·¸ë¦¬ê¸° (GUI ì œê±°ë¡œ ë”ë¯¸ í•¨ìˆ˜ í˜¸ì¶œ)
            frame = draw_danger_area(frame)
            
            # ì‚¬ëŒ ê²€ì¶œ
            bboxes, scores = detector.detect(frame)
            detections = []
            if len(bboxes) > 0:
                poses = pose_model.predict(frame, bboxes, scores)
                for pose, bbox in zip(poses, bboxes):
                    detections.append({
                        'bbox': bbox,
                        'keypoints': pose['keypoints'],
                        'score': pose['proposal_score']
                    })
            
            # íŠ¸ë˜í‚¹
            current_tracks = tracker.update(detections)
            current_time = time.time()
            
            # RAW ë°ì´í„°ìš© ë¦¬ìŠ¤íŠ¸ ë° ìœ„í—˜êµ¬ì—­ ê²½ê³  ë¦¬ìŠ¤íŠ¸
            raw_detections_list = []
            zone_warnings = []
            is_person_detected = len(current_tracks) > 0
            
            # ê° íŠ¸ë™ ì²˜ë¦¬
            for track_id in current_tracks:
                track = tracker.tracks[track_id]
                bbox = track['bbox']
                keypoints_list = track['keypoints']
                
                if len(keypoints_list) < 1: continue
                
                x1, y1, x2, y2 = bbox.astype(int)
                center_x, bottom_y = get_location_details(bbox)
                
                # --- [A] ìœ„í—˜êµ¬ì—­ ì²´í¬ (ZONE) ---
                in_zone = is_in_danger_zone(bbox, w, h)
                
                if in_zone:
                    if track_id not in zone_timers:
                        zone_timers[track_id] = current_time
                        alert_sent_zone[track_id] = False
                    
                    elapsed = current_time - zone_timers[track_id]
                    
                    # ğŸš¨ 1. ZONE CRITICAL ALERT (ì„ê³„ì¹˜ ì´ˆê³¼)
                    if elapsed >= ZONE_ALERT_TIME and not alert_sent_zone.get(track_id, False):
                        # ALERT ë©”ì‹œì§€ ë°œí–‰
                        alert_payload = {
                            "timestamp": now_str(),
                            "module": PE_MODULE,
                            "level": "CRITICAL", # ğŸš¨ CRITICAL ë ˆë²¨ ì ìš©
                            "message": f"ğŸš¨ DANGER ZONE CRITICAL: Worker #{track_id} in high-risk area for {elapsed:.1f}s. Immediate removal required.",
                            "details": [{"track_id": track_id, "action": "InDangerZoneCritical", "location": f"({center_x}, {bottom_y})"}]
                        }
                        publish_mqtt_message(mqtt_client, ALERT_TOPIC, alert_payload)
                        alert_sent_zone[track_id] = True
                        print(f"[{now_str()}] ğŸš¨ğŸš¨ [CRITICAL ALERT SENT] Zone alert for Worker #{track_id} ({elapsed:.1f}s)")

                    # âš ï¸ 2. ZONE WARNING (ê²½ê³  ì„ê³„ì¹˜ ì ‘ê·¼)
                    elif elapsed >= ZONE_WARNING_TIME and not alert_sent_zone.get(track_id, False): 
                        # CRITICAL ì„ê³„ì¹˜ ë„ë‹¬ ì „ê¹Œì§€ëŠ” WARNINGì„ ìœ ì§€
                        print(f"[{now_str()}] âš ï¸ [WARNING] Worker #{track_id} in zone for {elapsed:.1f}s.")
                        
                else:
                    if track_id in zone_timers:
                        del zone_timers[track_id]
                        alert_sent_zone[track_id] = False

                # --- [B] ë‚™ìƒ ê°ì§€ (FALL) ---
                current_kp = keypoints_list[-1]
                prev_kp = keypoints_list[-2] if len(keypoints_list) >= 2 else None
                
                action_name, confidence, details = detect_fall_rule_based(current_kp, prev_kp)
                
                if track_id not in fall_counters:
                    fall_counters[track_id] = 0
                    alert_sent_fall[track_id] = False
                
                is_fall_action = action_name in ['Fall Down', 'Lying Down'] and confidence >= FALL_CONFIDENCE_THRESHOLD
                
                if is_fall_action:
                    fall_counters[track_id] += 1
                else:
                    fall_counters[track_id] = 0
                    alert_sent_fall[track_id] = False # ì •ìƒ ìƒíƒœë¡œ ëŒì•„ì˜¤ë©´ ì•Œë¦¼ ìƒíƒœ ì´ˆê¸°í™”
                
                # ğŸš¨ 3. FALL CRITICAL ALERT (ë‚™ìƒ í™•ì •)
                if fall_counters[track_id] >= FALL_FRAMES and not alert_sent_fall.get(track_id, False):
                    alert_payload = {
                        "timestamp": now_str(),
                        "module": PE_MODULE,
                        "level": "CRITICAL", # ğŸš¨ CRITICAL ë ˆë²¨ ì ìš©
                        "message": f"ğŸš¨ CRITICAL FALL DETECTED: Worker #{track_id} is {action_name.lower()} at location ({center_x}, {bottom_y}). Immediate assistance required.",
                        "details": [{"track_id": track_id, "action": action_name, "confidence": float(confidence), "location": f"({center_x}, {bottom_y})"}]
                    }
                    publish_mqtt_message(mqtt_client, ALERT_TOPIC, alert_payload)
                    alert_sent_fall[track_id] = True
                    print(f"[{now_str()}] ğŸš¨ğŸš¨ [CRITICAL ALERT SENT] Fall alert for Worker #{track_id} @ {current_time:.2f}")

                # 4. RAW ë°ì´í„° ê¸°ë¡
                raw_detections_list.append({
                    "track_id": int(track_id),
                    "object_type": "Person",
                    "action": action_name,
                    "confidence": float(confidence),
                    "x_center": center_x,
                    "y_bottom": bottom_y,
                    "in_danger_zone": in_zone
                })
            
            try:
                # í”„ë ˆì„ ì••ì¶• (JPEG) ë° Base64 ì¸ì½”ë”©
                ret_enc, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 50]) 
                
                if ret_enc:
                    jpg_as_text = base64.b64encode(buffer.tobytes())
                    
                    # ìƒˆë¡œìš´ VIDEO í† í”½ (PE_VIDEO_TOPIC)ìœ¼ë¡œ ë°œí–‰ (QoS=0)
                    mqtt_client.publish(PE_VIDEO_TOPIC, jpg_as_text, qos=0) 
                    
                    if DEBUG_MODE:
                        # ë°œí–‰ ë¡œê·¸: DEBUG_MODEì¼ ë•Œë§Œ ì¶œë ¥
                        print(f"[{now_str()}] [PUB-PE-VIDEO] âœ… Base64 frame sent to {PE_VIDEO_TOPIC} (Size: {len(jpg_as_text)/1024:.1f} KB)")
                
            except Exception as e:
                print(f"[{now_str()}] [ERROR] âŒ PE Video streaming publish failed: {e}")
            # ===============================================================================
            
            # 4. RAW ë°ì´í„° ë°œí–‰ (ì£¼ê¸°ì ìœ¼ë¡œ)
            if frame_count % RAW_PUBLISH_INTERVAL == 0 and is_person_detected:
                raw_payload = {
                    "timestamp": now_str(),
                    "module": PE_MODULE, # PE ëª¨ë“ˆ ëª…ì‹œ
                    "level": "INFO", # ğŸš¨ INFO ë ˆë²¨ ì¶”ê°€ (ì •ìƒì ì¸ ë°ì´í„° íë¦„)
                    "detections": raw_detections_list,
                    "person_detected": is_person_detected
                }

                # ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•Šì€ ê²½ìš°
                if not is_person_detected:
                    raw_payload["message"] = "ì‚¬ëŒì´ ê°ì§€ë˜ì§€ ì•ŠìŒ."
                else:
                    # ë‚™ìƒ ì¤‘ì¸ ì‚¬ëŒ ìˆ˜ ê³„ì‚°
                    fall_count = sum(1 for d in raw_detections_list if d["action"] == "Fall Down")
                    total_count = len(raw_detections_list)
                    if fall_count > 0:
                        raw_payload["message"] = f"{total_count}ëª… ì¤‘ {fall_count}ëª… ë‚™ìƒ ê°ì§€ë¨."
                    else:
                        raw_payload["message"] = f"{total_count}ëª… ê°ì§€ë¨. ì´ìƒ ì—†ìŒ."

                mqtt_client.publish(RAW_TOPIC, json.dumps(raw_payload, ensure_ascii=False), qos=0)
                
                publish_mqtt_message(mqtt_client, RAW_TOPIC, raw_payload)
                # â­ï¸ ì‹œì—°ìš© ë¡œê·¸: RAW ë°ì´í„° ë°œí–‰ â­ï¸
                end_time = time.time()
                fps = 1.0 / (end_time - fps_time + 1e-6)
                fps_time = end_time
                print(f"[{now_str()}] [PUB-PE-RAW:INFO] âœ… RAW data sent (Tracks: {len(current_tracks)}) (FPS: {fps:.1f})")

            # ì§§ì€ ëŒ€ê¸° ì‹œê°„ì„ ì£¼ì–´ CPU ì‚¬ìš©ëŸ‰ì„ ë‚®ì¶¥ë‹ˆë‹¤.
            time.sleep(0.01) # ì•½ 100 FPS (ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œê°„ ì œì™¸)

        except KeyboardInterrupt:
            print(f"\n[{now_str()}] [INFO System] Measurement stopped by user (Ctrl+C).")
            break
        except Exception as e:
            print(f"\n[{now_str()}] [ERROR System] An unexpected error occurred: {e}")
            break
    
    # ì •ë¦¬
    if cap.isOpened():
        cap.release()
    
    print("\n" + "="*60)
    print("Program terminated. Closing MQTT connection.")
    mqtt_client.loop_stop()
    mqtt_client.disconnect()
    print("="*60)


if __name__ == '__main__':
    # TensorFlow ë¡œê·¸ë¥¼ ì–µì œí•˜ì—¬ í„°ë¯¸ë„ ì¶œë ¥ì„ ê¹”ë”í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' 
    main()
