import os
import glob
import torch
import torch.nn as nn
import numpy as np
from PIL import Image
from torchvision import transforms, models
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, recall_score, precision_score, precision_recall_curve
import matplotlib.pyplot as plt

# ==========================================================
# 1. ì´ˆê¸° í™˜ê²½ ì„¤ì • ë° ëª¨ë¸/ë°ì´í„°ì…‹ êµ¬ì¡° ì¬ì •ì˜ (1~4ë‹¨ê³„ì™€ ë™ì¼)
# ==========================================================

# ğŸš¨ í•™ìŠµ í™˜ê²½ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
DATA_ROOT = '/home/ubuntu26/workspace/AD_Dataset/' 
NORMAL_DIR = os.path.join(DATA_ROOT, 'normal_frames')
ANOMALY_DIR = os.path.join(DATA_ROOT, 'anomaly_frame')
IMAGE_SIZE = 224
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]
BATCH_SIZE = 32

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# --- 1-3. ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì¬ì •ì˜) ---
class ShipObstacleDataset(Dataset):
    def __init__(self, files, labels, transform=None):
        self.all_files = files
        self.all_labels = labels
        self.transform = transform
    def __len__(self): return len(self.all_files)
    def __getitem__(self, idx):
        img_path = self.all_files[idx]
        label = self.all_labels[idx]
        image = Image.open(img_path).convert('RGB')
        if self.transform: image = self.transform(image)
        label = torch.tensor(label, dtype=torch.float32) 
        return image, label

# --- 1-2. í…ŒìŠ¤íŠ¸ìš© ì „ì²˜ë¦¬ (í•™ìŠµê³¼ ë™ì¼) ---
val_test_transforms = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(MEAN, STD)
])

# --- 1-4. íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ---
normal_files = glob.glob(os.path.join(NORMAL_DIR, '*.jpg')) + glob.glob(os.path.join(NORMAL_DIR, '*.png'))
anomaly_files = glob.glob(os.path.join(ANOMALY_DIR, '*.jpg')) + glob.glob(os.path.join(ANOMALY_DIR, '*.png'))
files = normal_files + anomaly_files
labels = [0] * len(normal_files) + [1] * len(anomaly_files)

# --- 2-1. ë°ì´í„° ë¶„í•  (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ random_state ì‚¬ìš©í•´ì•¼ í•¨) ---
X_train, X_temp, y_train, y_temp = train_test_split(files, labels, test_size=0.2, random_state=42, stratify=labels)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

# --- 3ë‹¨ê³„. ëª¨ë¸ êµ¬ì¡° ì •ì˜ ë° ìµœì  ê°€ì¤‘ì¹˜ ë¡œë“œ ---
def build_model(num_classes=1, pretrained=True):
    model = models.resnet18(weights=None) # ê°€ì¤‘ì¹˜ íŒŒì¼ì—ì„œ ë¡œë“œí•˜ë¯€ë¡œ Noneìœ¼ë¡œ ì„¤ì •
    num_ftrs = model.fc.in_features
    model.fc = nn.Linear(num_ftrs, num_classes)
    return model

model = build_model(num_classes=1, pretrained=False) # ì‚¬ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê³  êµ¬ì¡°ë§Œ ê°€ì ¸ì˜´
model.load_state_dict(torch.load('best_obstacle_detection_model.pth', map_location=device)) # ğŸ”¥ ì €ì¥ëœ ìµœì  ê°€ì¤‘ì¹˜ ë¡œë“œ ğŸ”¥
model = model.to(device)
print(f"ìµœì  ëª¨ë¸ 'best_obstacle_detection_model.pth' ë¡œë“œ ì™„ë£Œ. ({device})")

# --- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ë¡œë” ì¤€ë¹„ ---
test_dataset = ShipObstacleDataset(X_test, y_test, val_test_transforms)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)


# ==========================================================
# 5-1. ì„±ëŠ¥ í‰ê°€ í•¨ìˆ˜ ì •ì˜ ë° ì‹¤í–‰ (Threshold 0.5)
# ==========================================================

def evaluate_model(model, data_loader, device, threshold=0.5):
    # model :  í•™ìŠµëœ ë”¥ëŸ¬ë‹ ëª¨ë¸(= ResNet18)
    # data_loader : í‰ê°€í•  ë°ì´í„°ì…‹ì„ ë‹´ì€ DataLoader
    # device : ì—°ì‚° ìˆ˜í–‰ì„ í•  í•˜ë“œì›¨ì–´ ì¥ì¹˜
    # threshold : ë¶„ë¥˜ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ì¤€ê°’(ì„ê³„ê°’)


    """ëª¨ë¸ì„ í‰ê°€í•˜ê³ , ì„±ëŠ¥ ì§€í‘œì™€ í™•ë¥  ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    model.eval() # ê²€ì¦ ëª¨ë“œ
    all_labels = [] # ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±
    all_probs = []
    
    with torch.no_grad():   # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™” ì‹œì¼œì¤Œ
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs).squeeze(1)
            probs = torch.sigmoid(outputs)  # 0~1ì˜ ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜ì‹œí‚´
            

            # labels.cpu(), probs.cpu() : GPU ë©”ëª¨ë¦¬ì— ìˆëŠ” í…Œì„œë¥¼ CPU ë©”ëª¨ë¦¬ì— ë³µì‚¬
            # .numpy() : ë³µì‚¬í•œ í…ì„œë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
            # .extend : ë¦¬ìŠ¤íŠ¸ì— ë°ì´í„° ì¶”ê°€
            all_labels.extend(labels.cpu().numpy())
            all_probs.extend(probs.cpu().numpy())

    # ìˆ˜ì§‘ëœ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
    # ë°ì´í„° í˜•ì‹ì˜ ìµœì¢… í†µì¼
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° í˜¸í™˜ì„± : F1-Score ë“± ê³„ì‚°í•˜ëŠ” Scikit-learn í•¨ìˆ˜ë“¤ì€ ë„˜íŒŒì´ ë°°ì—´ì„ í‘œì¤€ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ìš”êµ¬, ë¦¬ìŠ¤íŠ¸ ìƒíƒœë¡œëŠ” ê³„ì‹¼ í•¨ìˆ˜ì— ì§ì ‘ ë„£ì„ ìˆ˜ ì—†ìŒ
    # íš¨ìœ¨ì ì¸ ë°°ì—´ ì—°ì‚° : ë„˜íŒŒì´ ë°°ì—´ì€ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ëŒ€ê·œëª¨ ìˆ˜í•™ ì—°ì‚°ì„ ì§€ì›.        
    all_labels = np.array(all_labels)
    all_probs = np.array(all_probs)
    
    # ì„ê³„ê°’ ì ìš©
    # all_preds : ëª¨ë¸ì´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•´ ì¶œë ¥ ì´ìƒì¼ í™•ë¥ ì„ ëª¨ì•„ë†“ì€ ë„˜íŒŒì´ ë°°ì—´(0.0~1.0)
    # threshold ë³´ë‹¤ ì‘ì€ ì°¸, ì‘ìœ¼ë©´ ê±°ì§“
    # ì´ ì—°ì‚°ì˜ ê²°ê´€ëŠ” ì°¸, ê±°ì§“ìœ¼ë¡œ êµ¬ì„±ëœ ë¶ˆë¦¬ì–¸ ë°°ì—´
    # astype(int) : ë¶ˆë¦¬ì–¸ ë°°ì—´ì˜ ë°ì´í„° íƒ€ì…ì„ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    all_preds = (all_probs >= threshold).astype(int)
    
    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()
    # confusion_matrix :Scikit-learn ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ê¸°ë³¸ ë„êµ¬
    # all_labels : ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ ì‹¤ì œ ì •ë‹µ ë°°ì—´
    # all_preds : ëª¨ë¸ì´ ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡í•œ ê²°ê³¼
    # ì¶œë ¥ : ëª¨ë¸ì˜ ì˜ˆì¸¡ì´ ì–¼ë§ˆë‚˜ ì •í™•í–ˆëŠ”ì§€ë¥¼ 2X2 í–‰ë ¬ë¡œ ë°˜í™˜
    # ravel() : 2X2 í–‰ë ¬ì„ 1ì°¨ì› ë°°ì—´ë¡œ í¼ì³ì£¼ëŠ” ì—­í• 


    recall = recall_score(all_labels, all_preds, zero_division=0)
    # recall : ì¬í˜„ë¥ 
    # ì‹¤ì œ ì´ìƒì¸ ë°ì´í„° ì¤‘ì—ì„œ ëª¨ë¸ì´ ì´ìƒì´ë¼ê³  ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•œ ë¹„ìœ¨(= ì¥ì• ë¬¼ì¸ ê²ƒì„ ì¥ì• ë¬¼ì´ë¼ê³  í•˜ëŠ” ê²ƒ)
    # zero_division=0 : ë¶„ëª¨ê°€ 0ì¸ ìƒí™©ì—ì„œ ê³„ì‚°ì´ ì´ë£¨ì–´ì§€ì§€ ì•Šê¸° ë•Œë¬¸ì— ê°’ì„ 0ì´ë¼ê³  í•´ì„œ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ë¥¼ ë°©ì§€í•´ì¤Œ

    precision = precision_score(all_labels, all_preds, zero_division=0)
    # precision : ì •ë°€ë„
    # ëª¨ë¸ì´ ì´ìƒì´ë¼ê³  ì˜ˆì¸¡í•œ ëª¨ë“  ë°ì´í„° ì¤‘ì—ì„œ ì‹¤ì œë¡œ ì´ìƒì¸ ê²ƒì˜ ë¹„ìœ¨

    f1 = f1_score(all_labels, all_preds, zero_division=0)
    # f1 : ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· , ë‘ ì§€í‘œ ì¤‘ ì–´ëŠ í•˜ë‚˜ì—ë§Œ ì¹˜ìš°ì§€ì§€ ì•Šê³  ê· í˜• ì¡íŒ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ëŠ” ì§€í‘œ
    
    auc_roc = roc_auc_score(all_labels, all_probs)
    # AUC-ROC (ROC ê³¡ì„  ì•„ë˜ ë©´ì ) : ëª¨ë¸ì´ ë‘ í´ë˜ìŠ¤(ì •ìƒ, ì´ìƒ)ë¥¼ ì–¼ë§ˆë‚˜ ì˜ êµ¬ë¶„í•˜ëŠ”ì§€ì— ëŒ€í•´ ì „ë°˜ì ì¸ ëŠ¥ë ¥ì„ ë‚˜íƒ€ëƒ„
    
    results = {
        'TP (ì§„ì–‘ì„±)': tp, 'FN (ìœ„ìŒì„±)': fn, 'FP (ìœ„ì–‘ì„±)': fp, 'TN (ì§„ìŒì„±)': tn,
        'ì •ë°€ë„ (Precision)': precision,
        'ì¬í˜„ìœ¨ (Recall)': recall,
        'F1-Score': f1,
        'AUC-ROC': auc_roc
    }
    
    return results, all_probs, all_labels

# ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸ (ê¸°ë³¸ ì„ê³„ê°’ 0.5 ì‚¬ìš©)
test_results_05, test_probs, test_labels = evaluate_model(model, test_loader, device, threshold=0.5)

print("\n==========================================================")
print("--- 1ì°¨ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ê¸°ë³¸ ì„ê³„ê°’ 0.5) ---")
print("==========================================================")
for key, value in test_results_05.items():
    if isinstance(value, float):
        print(f"{key}: {value:.4f}")
    else:
        print(f"{key}: {value}")


# ==========================================================
# 5-2. ìµœì  ì„ê³„ê°’ ê²°ì • ë° ìµœì¢… í‰ê°€
# ==========================================================

# F1-Scoreê°€ ìµœëŒ€ì¸ ì§€ì ì„ ì°¾ì•„ ìµœì  ì„ê³„ê°’ ê²°ì •
precision_list, recall_list, thresholds = precision_recall_curve(test_labels, test_probs)
# precision_recall_curve : ì„ê³„ê°’ì„ 0ë¶€í„° 1ê¹Œì§€ ë¯¸ì„¸í•˜ê²Œ ë³€í™”ì‹œí‚¬ ë•Œë§ˆë‹¤ ëª¨ë¸ì˜ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ê³„ì‚°í•´ì„œ ì„¸ ê°€ì§€ ë°°ì—´ ë°˜í™˜
# precision_list : ê° ì„ê³„ê°’ì—ì„œì˜ ì •ë°€ë„ ê°’ ëª©ë¡
# recall_list : ê° ì„ê³„ê°’ì—ì„œì˜ ì¬í˜„ìœ¨ ê°’ ëª©ë¡
# thresholds : ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì´ ê³„ì‚°ëœ í•´ë‹¹ ì„ê³„ê°’ ëª©ë¡
fscores = 2 * (precision_list * recall_list) / (precision_list + recall_list + 1e-6)
optimal_idx = np.argmax(fscores)
optimal_threshold = thresholds[optimal_idx]

# ìµœì  ì„ê³„ê°’ ì ìš© í›„ ìµœì¢… í‰ê°€
final_test_results_optimized, _, _ = evaluate_model(model, test_loader, device, threshold=optimal_threshold)

print("\n==========================================================")
print(f"--- 2ì°¨ ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ (ìµœì  ì„ê³„ê°’ {optimal_threshold:.4f} ì ìš©) ---")
print("==========================================================")
for key, value in final_test_results_optimized.items():
    if isinstance(value, float):
        print(f"{key}: {value:.4f}")
    else:
        print(f"{key}: {value}")


# ==========================================================
# 6ë‹¨ê³„: ê²°ê³¼ ì‹œê°í™” ë° ì˜¤ë¥˜ ë¶„ì„ (ê¸°ë³¸ Python ë°˜ë³µë¬¸ ì‚¬ìš©)
# ==========================================================

# 6-1. ì„±ëŠ¥ ê³¡ì„  ì‹œê°í™” (5ë‹¨ê³„ ë³€ìˆ˜ ì‚¬ìš©)
plt.figure(figsize=(8, 6))
plt.plot(recall_list, precision_list, marker='.', label='Precision-Recall Curve')
plt.plot(recall_list[optimal_idx], precision_list[optimal_idx], 'o', color='red', 
         label=f'Optimal Threshold ({optimal_threshold:.4f}, F1: {fscores[optimal_idx]:.4f})')
plt.xlabel('ì¬í˜„ìœ¨ (Recall)')
plt.ylabel('ì •ë°€ë„ (Precision)')
plt.title('ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„  (Precision-Recall Curve)')
plt.legend()
plt.grid(True)
# plt.show() # ì‹œê°í™”ë¥¼ ì›í•˜ë©´ ì£¼ì„ í•´ì œ (ì£¼í”¼í„°/Colab í™˜ê²½ ê¶Œì¥)

# 6-2. ì˜¤ë¥˜ ë¶„ì„ (ê¸°ë³¸ Python ë°©ì‹)
false_negatives_list = []
false_positives_list = []
num_test_samples = len(X_test)

# ëª¨ë“  í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì„ ìˆœíšŒí•˜ë©° ì˜¤ë¥˜ë¥¼ ê²€ì‚¬
for i in range(num_test_samples):
    filepath = X_test[i]
    label = int(test_labels[i])
    prob = test_probs[i]
    
    # ìµœì  ì„ê³„ê°’ì„ ì ìš©í•œ ì˜ˆì¸¡ ê²°ê³¼
    prediction = 1 if prob >= optimal_threshold else 0
    
    # 1. ìœ„ìŒì„± (FN) ê²€ì‚¬: ì‹¤ì œ ì´ìƒ(1)ì¸ë° ì˜ˆì¸¡ì´ ì •ìƒ(0)ì¸ ê²½ìš°
    if label == 1 and prediction == 0:
        false_negatives_list.append({
            'filepath': filepath,
            'predicted_prob': prob
        })
        
    # 2. ìœ„ì–‘ì„± (FP) ê²€ì‚¬: ì‹¤ì œ ì •ìƒ(0)ì¸ë° ì˜ˆì¸¡ì´ ì´ìƒ(1)ì¸ ê²½ìš°
    elif label == 0 and prediction == 1:
        false_positives_list.append({
            'filepath': filepath,
            'predicted_prob': prob
        })

print("\n==========================================================")
print("--- 6ë‹¨ê³„: ì˜¤ë¥˜ ë¶„ì„ ê²°ê³¼ (ê¸°ë³¸ Python ë¦¬ìŠ¤íŠ¸) ---")
print("==========================================================")

# ìœ„ìŒì„± ê²°ê³¼ ì¶œë ¥
print(f"** ìœ„ìŒì„± (FN) íŒŒì¼ ìˆ˜: {len(false_negatives_list)} ê°œ **")
if false_negatives_list:
    print("FN íŒŒì¼ ëª©ë¡ (ê²½ë¡œ ë° ì˜ˆì¸¡ í™•ë¥ ):")
    for item in false_negatives_list:
        print(f"  ê²½ë¡œ: {item['filepath']}, í™•ë¥ : {item['predicted_prob']:.4f}")
else:
    print("ìœ„ìŒì„± íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ëª¨ë¸ ì„±ëŠ¥ ì™„ë²½)")

# ìœ„ì–‘ì„± ê²°ê³¼ ì¶œë ¥
print(f"\n** ìœ„ì–‘ì„± (FP) íŒŒì¼ ìˆ˜: {len(false_positives_list)} ê°œ **")
if false_positives_list:
    print("FP íŒŒì¼ ëª©ë¡ (ê²½ë¡œ ë° ì˜ˆì¸¡ í™•ë¥ ):")
    for item in false_positives_list:
        print(f"  ê²½ë¡œ: {item['filepath']}, í™•ë¥ : {item['predicted_prob']:.4f}")
else:
    print("ìœ„ì–‘ì„± íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ëª¨ë¸ ì •ë°€ë„ 100%)")