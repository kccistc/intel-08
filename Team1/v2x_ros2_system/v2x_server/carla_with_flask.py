#!/usr/bin/env python
# -*- coding: utf-8 -*-

# carla ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì´ì œ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬ ë˜ëŠ” ì‚­ì œ
# import carla
import requests # ğŸ’¡ HTTP ìš”ì²­ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import time
import cv2
import numpy as np
from openvino import Core
from flask import Flask, Response, jsonify
import threading
import os
from datetime import datetime
import json

# --- ì„¤ì •ê°’ ---
CARLA_BRIDGE_URL = "http://localhost:5001" # ğŸ’¡ CARLA ë¸Œë¦¿ì§€ ì„œë²„ ì£¼ì†Œ

app = Flask(__name__)
# ì›ë³¸ í”„ë ˆì„ì€ ì´ì œ ë¸Œë¦¿ì§€ì—ì„œ ë°›ì•„ì˜¤ë¯€ë¡œ, ì²˜ë¦¬ëœ í”„ë ˆì„ë§Œ ì €ì¥
processed_frames = {'cctv1': np.zeros((480, 720, 3), dtype=np.uint8), 'cctv2': np.zeros((480, 720, 3), dtype=np.uint8)}
detection_status = {'cctv1': False, 'cctv2': False}
status_lock = threading.Lock()

# camera_callback í•¨ìˆ˜ëŠ” ì´ì œ carla_bridge.pyì— ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì‚­ì œí•©ë‹ˆë‹¤.

class InferencePlayer: # ğŸ’¡ í´ë˜ìŠ¤ ì´ë¦„ì„ ë” ëª…í™•í•˜ê²Œ ë³€ê²½
    def __init__(self):
        self.is_running = True
        self.warning_sent_times = {'cctv1': 0, 'cctv2': 0}
        self.warning_cooldown = 5 # 5ì´ˆ ê°„ê²©
        
        # ğŸ’¡ ì¹´ë©”ë¼ ìœ„ì¹˜ëŠ” í•˜ë“œì½”ë”©í•˜ê±°ë‚˜, ë¸Œë¦¿ì§€ì—ì„œ APIë¡œ ì œê³µë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ í•˜ë“œì½”ë”©.
        self.camera_locations = {
            'cctv1': {'x': 5, 'y': -172.62, 'z': 22.35},
            'cctv2': {'x': -20, 'y': 22, 'z': 24}
        }

        # (OpenVINO ëª¨ë¸ ì´ˆê¸°í™” ë¶€ë¶„ì€ ë³€ê²½ì‚¬í•­ ì—†ìŒ)
        self.model1_xml_path = "./model1.xml"; self.model1_bin_path = "./model1.bin"
        self.model2_xml_path = "./model2.xml"; self.model2_bin_path = "./model2.bin"
        self.device = "CPU"; self.confidence_threshold = 0.3; self.input_h, self.input_w = 640, 640
        core = Core()
        model1 = core.read_model(model=self.model1_xml_path, weights=self.model1_bin_path)
        model1.reshape([1, 3, self.input_h, self.input_w])
        self.compiled_model1 = core.compile_model(model=model1, device_name=self.device)
        self.output_layer1 = self.compiled_model1.output(0)
        model2 = core.read_model(model=self.model2_xml_path, weights=self.model2_bin_path)
        model2.reshape([1, 3, self.input_h, self.input_w])
        self.compiled_model2 = core.compile_model(model=model2, device_name=self.device)
        self.output_layer2 = self.compiled_model2.output(0)
        print("âœ… OpenVINO ëª¨ë¸ 2ê°œ ë¡œë“œ ì™„ë£Œ.")

    # (send_v2x_warning í•¨ìˆ˜ëŠ” ë³€ê²½ì‚¬í•­ ì—†ìŒ)
    def send_v2x_warning(self, camera_name, frame):
        current_time = time.time()
        if current_time - self.warning_sent_times.get(camera_name, 0) < self.warning_cooldown:
            return
        
        now = datetime.now()
        timestamp_str = now.strftime("%Y%m%d_%H%M%S")

        # JSON ì´ë²¤íŠ¸ ì €ì¥
        MESSAGE_DIR = "./events"
        os.makedirs(MESSAGE_DIR, exist_ok=True)
        json_filename = f"event_{camera_name}_{timestamp_str}.json"
        json_filepath = os.path.join(MESSAGE_DIR, json_filename)

        event_data = {
            "timestamp": now.isoformat(),
            "camera_id": camera_name,
            "event_type": "accident_detected",
            "location": self.camera_locations.get(camera_name, "Unknown")
        }

        try:
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(event_data, f, indent=4, ensure_ascii=False)
            print(f"âœ… ì´ë²¤íŠ¸ ì •ë³´ë¥¼ '{json_filepath}' ê²½ë¡œì— JSON íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"â—ï¸[ì˜¤ë¥˜] JSON íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        

        self.warning_sent_times[camera_name] = current_time

    # ğŸ’¡ CARLA ê´€ë ¨ í•¨ìˆ˜(setup_simulation, _setup_sensors, cleanup)ëŠ” ëª¨ë‘ ì‚­ì œ
    
    def run_inference_on_frame(self, frame, compiled_model, output_layer, camera_name, timestamp_str):
        original_h, original_w = frame.shape[:2]; resized_image = cv2.resize(frame, (self.input_w, self.input_h))
        transposed_image = resized_image.transpose(2, 0, 1); input_tensor = np.expand_dims(transposed_image, axis=0).astype(np.float32) / 255.0
        results = compiled_model([input_tensor])[output_layer]; detections = results[0]
        detection_found = False
        boxes = []
        for detection in detections:
            x1, y1, x2, y2, confidence = detection
            if confidence >= self.confidence_threshold:
                if not detection_found: # ì²« ê°ì§€ ì‹œì—ë§Œ ì´ë¯¸ì§€ ì €ì¥
                    detection_found = True
                    # í”„ë ˆì„ ì´ë¯¸ì§€ ì €ì¥ (ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° ì „)
                    IMAGE_DIR = f"./accident_{camera_name}"
                    os.makedirs(IMAGE_DIR, exist_ok=True)
                    image_filename = f"frame_{timestamp_str}.jpg"
                    image_filepath = os.path.join(IMAGE_DIR, image_filename)
                    
                    try:
                        cv2.imwrite(image_filepath, frame)
                        print(f"âœ… ì‚¬ê³  í”„ë ˆì„ì„ '{image_filepath}' ê²½ë¡œì— ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                    except Exception as e:
                        print(f"â—ï¸[ì˜¤ë¥˜] í”„ë ˆì„ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

                x1_s, y1_s = int(x1 * original_w / self.input_w), int(y1 * original_h / self.input_h)
                x2_s, y2_s = int(x2 * original_w / self.input_w), int(y2 * original_h / self.input_h)
                cv2.rectangle(frame, (x1_s, y1_s), (x2_s, y2_s), (0, 0, 255), 2)
                cv2.putText(frame, f"accident : {confidence:.2f}", (x1_s, y1_s - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                boxes.append((x1_s, y1_s, x2_s, y2_s, confidence))
        return frame, detection_found, boxes

    def get_frame_from_bridge(self, camera_name):
        """ğŸ’¡ CARLA ë¸Œë¦¿ì§€ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
        try:
            response = requests.get(f"{CARLA_BRIDGE_URL}/get_frame/{camera_name}", timeout=0.5)
            if response.status_code == 200:
                # ì‘ë‹µ ë°›ì€ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ Numpy ë°°ì—´(ì´ë¯¸ì§€)ë¡œ ë””ì½”ë”©
                np_arr = np.frombuffer(response.content, np.uint8)
                return cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
        except requests.exceptions.RequestException as e:
            # print(f"ë¸Œë¦¿ì§€ ì—°ê²° ì˜¤ë¥˜: {e}") # ë„ˆë¬´ ìì£¼ ì¶œë ¥ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬
            pass
        return None # ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

    def run(self):
        """ğŸ’¡ ë©”ì¸ ë¡œì§: ë¸Œë¦¿ì§€ì—ì„œ í”„ë ˆì„ì„ ë°›ì•„ì™€ ì¶”ë¡  ì‹¤í–‰"""
        print("âœ… ì¶”ë¡  í”Œë ˆì´ì–´ ì‹œì‘. CARLA ë¸Œë¦¿ì§€ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.")
        while self.is_running:
            # ê° ì¹´ë©”ë¼ì— ëŒ€í•´ ë¸Œë¦¿ì§€ì—ì„œ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
            frame1 = self.get_frame_from_bridge('cctv1')
            frame2 = self.get_frame_from_bridge('cctv2')
            
            now = datetime.now()
            timestamp_str = now.strftime("%Y%m%d_%H%M%S_%f")

            if frame1 is not None:
                cctv1_processed, detected1, boxes1 = self.run_inference_on_frame(frame1, self.compiled_model1, self.output_layer1, 'cctv1', timestamp_str)
                if detected1: self.send_v2x_warning('cctv1', cctv1_processed)
                with status_lock:
                    detection_status['cctv1'] = detected1
                processed_frames['cctv1'] = cctv1_processed
            
            if frame2 is not None:
                cctv2_processed, detected2, boxes2 = self.run_inference_on_frame(frame2, self.compiled_model2, self.output_layer2, 'cctv2', timestamp_str)
                if detected2: self.send_v2x_warning('cctv2', cctv2_processed)
                with status_lock:
                    detection_status['cctv2'] = detected2
                processed_frames['cctv2'] = cctv2_processed
            
            time.sleep(0.03) # ë£¨í”„ ê°„ê²© ì¡°ì ˆ

    def quit(self): 
        self.is_running = False

# (ì´í•˜ Flask API ë° main í•¨ìˆ˜ëŠ” ê±°ì˜ ë™ì¼)
def generate_frame(camera_name):
    while True:
        with status_lock:
            frame = processed_frames[camera_name].copy()
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
        frame_bytes = buffer.tobytes()
        yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
        time.sleep(0.03)

@app.route('/video_feed/cctv1')
def video_feed_cctv1(): return Response(generate_frame('cctv1'), mimetype='multipart/x-mixed-replace; boundary=frame')
@app.route('/video_feed/cctv2')
def video_feed_cctv2(): return Response(generate_frame('cctv2'), mimetype='multipart/x-mixed-replace; boundary=frame')
@app.route('/health')
def health(): return {'status': 'running'}
@app.route('/api/status')
def api_status():
    with status_lock: return jsonify(detection_status)

def run_flask():
    print("ğŸŒ ë©”ì¸ Flask ì„œë²„ ì‹œì‘ - http://localhost:5000"); app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)

def main():
    player = None
    try:
        flask_thread = threading.Thread(target=run_flask, daemon=True); flask_thread.start()
        # ğŸ’¡ CARLA í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë¶€ë¶„ ì‚­ì œ, InferencePlayer ìƒì„± ë° ì‹¤í–‰
        player = InferencePlayer()
        player.run()
    except KeyboardInterrupt: 
        print("\ní”„ë¡œê·¸ë¨ ì¢…ë£Œ ìš”ì²­...")
    finally:
        if player: 
            player.quit()
            # cleanupì€ carla_bridge.pyì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” í˜¸ì¶œ ì•ˆ í•¨

if __name__ == '__main__': 
    main()